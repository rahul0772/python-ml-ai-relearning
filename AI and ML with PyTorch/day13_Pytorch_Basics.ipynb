{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJrM5jfIzramHOEl0EStDZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahul0772/python-ml-ai-relearning/blob/main/AI%20and%20ML%20with%20PyTorch/day13_Pytorch_Basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pytorch Basics"
      ],
      "metadata": {
        "id": "flME4ZWUoF-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# PYTORCH FROM SCRATCH\n",
        "# ============================================================\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 1Ô∏è‚É£ WHAT IS PYTORCH?\n",
        "# ============================================================\n",
        "\n",
        "# PyTorch is a Python library used for:\n",
        "# - Machine Learning\n",
        "# - Deep Learning\n",
        "# - Neural Networks\n",
        "#\n",
        "# PyTorch helps us:\n",
        "# - Work with numbers (tensors)\n",
        "# - Automatically calculate gradients (backpropagation)\n",
        "# - Build and train neural networks easily\n",
        "#\n",
        "# BIG IDEA:\n",
        "# PyTorch = NumPy + Automatic Differentiation + GPU support\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 2Ô∏è‚É£ INSTALL & IMPORT PYTORCH\n",
        "# ============================================================\n",
        "\n",
        "# In Google Colab, PyTorch is already installed\n",
        "# So we just import it\n",
        "\n",
        "import torch\n",
        "\n",
        "# torch is the main PyTorch library\n",
        "# Everything we do will use this\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 3Ô∏è‚É£ WHAT IS A TENSOR? (VERY IMPORTANT)\n",
        "# ============================================================\n",
        "\n",
        "# A tensor is like:\n",
        "# - a number (0D tensor)\n",
        "# - a list (1D tensor)\n",
        "# - a table (2D tensor)\n",
        "# - higher dimensional data (3D, 4D...)\n",
        "\n",
        "# Think:\n",
        "# Tensor = PyTorch version of NumPy array\n",
        "\n",
        "# Creating a simple tensor (single number) / 0-dimensional tensor\n",
        "# torch.tensor() takes Python data (number, list, list of lists) and converts it into a tensor, which is the basic data type PyTorch uses for all computations\n",
        "# A TENSOR object that holds the value 5\n",
        "a = torch.tensor(5)\n",
        "\n",
        "# Print tensor\n",
        "print(\"Tensor a:\", a)\n",
        "\n",
        "# Check type\n",
        "print(\"Type of a:\", type(a))\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 4Ô∏è‚É£ 1D TENSOR (VECTOR)\n",
        "# ============================================================\n",
        "\n",
        "# A list of\n",
        "# Create a 1D pytorch tensor contsaining the number 1 through 5 (a vector of length 5)\n",
        "b = torch.tensor([1, 2, 3, 4, 5])\n",
        "\n",
        "print(\"\\nTensor b:\", b)\n",
        "print(\"Shape of b:\", b.shape)\n",
        "\n",
        "# shape tells how many elements and dimensions\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 5Ô∏è‚É£ 2D TENSOR (MATRIX)\n",
        "# ============================================================\n",
        "\n",
        "# Like a table (rows and columns)\n",
        "# Creates a 2√ó3 PyTorch tensor (a matrix) with 2 rows and 3 columns.\n",
        "c = torch.tensor([\n",
        "    [1, 2, 3],\n",
        "    [4, 5, 6]\n",
        "])\n",
        "\n",
        "print(\"\\nTensor c:\\n\", c)\n",
        "print(\"Shape of c:\", c.shape)\n",
        "\n",
        "# Shape (2,3) means:\n",
        "# 2 rows\n",
        "# 3 columns\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 6Ô∏è‚É£ CREATING TENSORS USING PYTORCH FUNCTIONS\n",
        "# ============================================================\n",
        "\n",
        "# Zeros tensor\n",
        "zeros = torch.zeros(3, 3)\n",
        "print(\"\\nZeros tensor:\\n\", zeros)\n",
        "\n",
        "# Ones tensor\n",
        "ones = torch.ones(2, 2)\n",
        "print(\"\\nOnes tensor:\\n\", ones)\n",
        "\n",
        "# Random tensor\n",
        "random = torch.rand(2, 3)\n",
        "print(\"\\nRandom tensor:\\n\", random)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 7Ô∏è‚É£ BASIC TENSOR OPERATIONS\n",
        "# ============================================================\n",
        "\n",
        "x = torch.tensor([1, 2, 3])\n",
        "y = torch.tensor([4, 5, 6])\n",
        "\n",
        "# Addition\n",
        "print(\"\\nAddition:\", x + y)\n",
        "\n",
        "# Subtraction\n",
        "print(\"Subtraction:\", x - y)\n",
        "\n",
        "# Multiplication (element-wise)\n",
        "print(\"Multiplication:\", x * y)\n",
        "\n",
        "# Division\n",
        "print(\"Division:\", x / y)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 8Ô∏è‚É£ AUTOGRAD (MAGIC OF PYTORCH)\n",
        "# ============================================================\n",
        "\n",
        "# Autograd automatically calculates gradients\n",
        "# Gradients are needed for learning (training neural networks)\n",
        "\n",
        "# requires_grad=True tells PyTorch:\n",
        "# \"Track this tensor for gradient calculation\"\n",
        "\n",
        "x = torch.tensor(2.0, requires_grad=True)\n",
        "\n",
        "# Simple math operation\n",
        "y = x * x * 3   # y = 3x^2\n",
        "\n",
        "# Backpropagation\n",
        "y.backward()\n",
        "\n",
        "# Gradient of y with respect to x\n",
        "print(\"\\nValue of x:\", x)\n",
        "print(\"y = 3x^2\")\n",
        "print(\"Gradient dy/dx:\", x.grad)\n",
        "\n",
        "# Math check:\n",
        "# y = 3x^2\n",
        "# dy/dx = 6x\n",
        "# at x=2 ‚Üí 6*2 = 12 ‚úîÔ∏è\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 9Ô∏è‚É£ SIMPLE LINEAR MODEL (y = wx + b)\n",
        "# ============================================================\n",
        "\n",
        "# This is the MOST BASIC neural network\n",
        "\n",
        "# Create parameters (weights)\n",
        "w = torch.tensor(1.0, requires_grad=True)\n",
        "b = torch.tensor(0.0, requires_grad=True)\n",
        "\n",
        "# Input\n",
        "x = torch.tensor(2.0)\n",
        "\n",
        "# Forward pass (prediction)\n",
        "y_pred = w * x + b\n",
        "\n",
        "print(\"\\nPrediction y:\", y_pred)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# üîü LOSS FUNCTION\n",
        "# ============================================================\n",
        "\n",
        "# Loss tells us \"how wrong our prediction is\"\n",
        "\n",
        "# True value\n",
        "y_true = torch.tensor(4.0)\n",
        "\n",
        "# Mean Squared Error (MSE)\n",
        "loss = (y_pred - y_true) ** 2\n",
        "\n",
        "print(\"Loss:\", loss)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 1Ô∏è‚É£1Ô∏è‚É£ BACKPROPAGATION\n",
        "# ============================================================\n",
        "\n",
        "# Calculate gradients\n",
        "loss.backward()\n",
        "\n",
        "print(\"\\nGradient of w:\", w.grad)\n",
        "print(\"Gradient of b:\", b.grad)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 1Ô∏è‚É£2Ô∏è‚É£ MANUAL GRADIENT DESCENT\n",
        "# ============================================================\n",
        "\n",
        "# Learning rate\n",
        "lr = 0.01\n",
        "\n",
        "# Update parameters\n",
        "with torch.no_grad():\n",
        "    w -= lr * w.grad\n",
        "    b -= lr * b.grad\n",
        "\n",
        "# Reset gradients (VERY IMPORTANT)\n",
        "w.grad.zero_()\n",
        "b.grad.zero_()\n",
        "\n",
        "print(\"\\nUpdated w:\", w)\n",
        "print(\"Updated b:\", b)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 1Ô∏è‚É£3Ô∏è‚É£ TRAINING LOOP (REAL LEARNING)\n",
        "# ============================================================\n",
        "\n",
        "# Simple dataset\n",
        "X = torch.tensor([1.0, 2.0, 3.0, 4.0])\n",
        "Y = torch.tensor([2.0, 4.0, 6.0, 8.0])\n",
        "\n",
        "# Initialize parameters\n",
        "w = torch.tensor(0.0, requires_grad=True)\n",
        "b = torch.tensor(0.0, requires_grad=True)\n",
        "\n",
        "# Training\n",
        "for epoch in range(20):\n",
        "\n",
        "    # Forward pass\n",
        "    y_pred = w * X + b\n",
        "\n",
        "    # Loss\n",
        "    loss = ((y_pred - Y) ** 2).mean()\n",
        "\n",
        "    # Backward\n",
        "    loss.backward()\n",
        "\n",
        "    # Update\n",
        "    with torch.no_grad():\n",
        "        w -= 0.01 * w.grad\n",
        "        b -= 0.01 * b.grad\n",
        "\n",
        "    # Zero gradients\n",
        "    w.grad.zero_()\n",
        "    b.grad.zero_()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}: Loss={loss.item():.4f}\")\n",
        "\n",
        "print(\"\\nFinal w:\", w.item())\n",
        "print(\"Final b:\", b.item())\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# üéâ CONGRATULATIONS\n",
        "# ============================================================\n",
        "\n",
        "# You just learned:\n",
        "# - What PyTorch is\n",
        "# - What tensors are\n",
        "# - Autograd (backpropagation)\n",
        "# - Loss functions\n",
        "# - Gradient descent\n",
        "# - Training a model from scratch\n",
        "#\n",
        "# NEXT STEPS (when you click \"next\"):\n",
        "# - torch.nn\n",
        "# - torch.optim\n",
        "# - Real neural networks\n",
        "# - CNNs, RNNs, Transformers\n",
        "#\n",
        "# SAVE THIS CELL AS YOUR NOTES ‚ù§Ô∏è\n",
        "# ============================================================\n"
      ],
      "metadata": {
        "id": "NKgPCJ4VoJ2-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}